{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob \n",
    "import pandas as pd\n",
    "import string\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import models.lossnet as lossnet\n",
    "import models.crnn as crnn\n",
    "from config import *\n",
    "from sampler import SubsetSequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob(os.path.join('./Large_Captcha_Dataset', '*.png'))\n",
    "path = './Large_Captcha_Dataset'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data.remove(os.path.join('./Large_Captcha_Dataset', '4q2wA.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_uppercase + string.ascii_lowercase + string.digits\n",
    "\n",
    "mapping = {}\n",
    "mapping_inv = {}\n",
    "i = 1\n",
    "for x in all_letters:\n",
    "    mapping[x] = i\n",
    "    mapping_inv[i] = x\n",
    "    i += 1\n",
    "\n",
    "num_class = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "datas = collections.defaultdict(list)\n",
    "for d in data:\n",
    "    x = d.split('/')[-1]\n",
    "    datas['image'].append(x)\n",
    "    datas['label'].append([mapping[i] for i in x.split('.')[0]])\n",
    "df = pd.DataFrame(datas)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset:\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.iloc[idx]\n",
    "        image = Image.open(os.path.join(path, data['image'])).convert('L')\n",
    "        label = torch.tensor(data['label'], dtype=torch.int32)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4914,], [0.2023,])\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4914,], [0.2023,])\n",
    "])\n",
    "\n",
    "trainset = CaptchaDataset(df_train, train_transform)\n",
    "unlabeledset = CaptchaDataset(df_train, test_transform)\n",
    "testset = CaptchaDataset(df_test, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Prediction Loss\n",
    "def LossPredLoss(input, target, margin=1.0, reduction='mean'):\n",
    "    assert len(input) % 2 == 0, 'the batch size is not even.'\n",
    "    assert input.shape == input.flip(0).shape\n",
    "    \n",
    "    input = (input - input.flip(0))[:len(input)//2] # [l_1 - l_2B, l_2 - l_2B-1, ... , l_B - l_B+1], where batch_size = 2B\n",
    "    target = (target - target.flip(0))[:len(target)//2]\n",
    "    target = target.detach()\n",
    "\n",
    "    one = 2 * torch.sign(torch.clamp(target, min=0)) - 1 # 1 operation which is defined by the authors\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        loss = torch.sum(torch.clamp(margin - one * input, min=0))\n",
    "        loss = loss / input.size(0) # Note that the size of input is already halved\n",
    "    elif reduction == 'none':\n",
    "        loss = torch.clamp(margin - one * input, min=0)\n",
    "    else:\n",
    "        NotImplementedError()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty(models, criterion, unlabeled_loader):\n",
    "    models['backbone'].eval()\n",
    "    models['module'].eval()\n",
    "    uncertainty = torch.tensor([]).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in unlabeled_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            scores, features, _ = models['backbone'](inputs, labels, criterion)\n",
    "            pred_loss = models['module'](features) # pred_loss = criterion(scores, labels) # ground truth loss\n",
    "            pred_loss = pred_loss.view(pred_loss.size(0))\n",
    "\n",
    "            uncertainty = torch.cat((uncertainty, pred_loss), 0)\n",
    "    \n",
    "    return uncertainty.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(outputs):\n",
    "    result = []\n",
    "    for i in range(len(outputs)):\n",
    "        pred = []\n",
    "        then = 0\n",
    "        for x in outputs[i]:\n",
    "            if then != x and x > 0 :\n",
    "                pred.append(x)\n",
    "                if len(pred) == 5:\n",
    "                    break\n",
    "            then = x\n",
    "        if len(pred) < 5:\n",
    "            for i in range(5-len(pred)):\n",
    "                pred.append(0)\n",
    "        result.append(pred)\n",
    "    result = torch.LongTensor(result).cuda()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Utils\n",
    "iters = 0\n",
    "\n",
    "#\n",
    "def train_epoch(models, criterion, optimizers, dataloaders, epoch, epoch_loss):\n",
    "    models['backbone'].train()\n",
    "    models['module'].train()\n",
    "    global iters\n",
    "\n",
    "    # loss_cum_1, loss_cum_2 = 0, 0\n",
    "\n",
    "    pbar = tqdm(dataloaders['train'], leave=False, total=len(dataloaders['train']))\n",
    "    for data in pbar:\n",
    "        inputs = data[0].cuda()\n",
    "        labels = data[1].cuda()\n",
    "        iters += 1\n",
    "\n",
    "        optimizers['backbone'].zero_grad()\n",
    "        optimizers['module'].zero_grad()\n",
    "\n",
    "        scores, features, target_loss = models['backbone'](inputs, labels, criterion)\n",
    "        # target_loss = target_loss.log_softmax(-1)\n",
    "        # target_loss = criterion(scores, labels)\n",
    "\n",
    "        if epoch > epoch_loss:\n",
    "            # After 120 epochs, stop the gradient from the loss prediction module propagated to the target model.\n",
    "            features[0] = features[0].detach()\n",
    "            features[1] = features[1].detach()\n",
    "            features[2] = features[2].detach()\n",
    "            # features[3] = features[3].detach()\n",
    "        pred_loss = models['module'](features)\n",
    "        pred_loss = pred_loss.view(pred_loss.size(0))\n",
    "\n",
    "        m_backbone_loss = torch.sum(target_loss) / target_loss.size(0)\n",
    "        m_module_loss   = LossPredLoss(pred_loss, target_loss, margin=MARGIN)\n",
    "        loss            = m_backbone_loss + WEIGHT * m_module_loss\n",
    "\n",
    "        pbar.set_description(f'b_loss : {m_backbone_loss:.3f}, m_loss : {m_module_loss:.3f}, loss : {loss:.3f}')\n",
    "        # loss_cum_1 += m_backbone_loss\n",
    "        # loss_cum_2 += m_module_loss\n",
    "        # print(f'm_backbone_loss : {m_backbone_loss}, m_module_loss : {m_module_loss}, loss : {loss}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizers['backbone'].step()\n",
    "        optimizers['module'].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, criterion, dataloaders, mode='val'):\n",
    "    print('>> Test a Model.')\n",
    "    assert mode == 'val' or mode == 'test'\n",
    "    models['backbone'].eval()\n",
    "    models['module'].eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(dataloaders[mode]):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            scores, _, _ = models['backbone'](inputs, labels, criterion)\n",
    "            scores = scores.permute(1, 0, 2)\n",
    "            _, preds = torch.max(scores.data, 2)\n",
    "            preds = predict(preds)\n",
    "            total += labels.size(0)\n",
    "            for i in range(len(preds)):\n",
    "                correct += torch.equal(preds[i], labels[i])\n",
    "\n",
    "            if idx >= 999:\n",
    "                break\n",
    "    \n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, criterion, optimizers, dataloaders, num_epochs, epoch_loss):\n",
    "    print('>> Train a Model.')\n",
    "    checkpoint_dir = os.path.join('./checkpoints', 'train', 'weights')\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch(models, criterion, optimizers, dataloaders, epoch, epoch_loss)\n",
    "\n",
    "        # Save a checkpoint\n",
    "        if False and epoch % 10 == 0:\n",
    "            pass\n",
    "            # acc = test(models, criterion, dataloaders, mode='test')\n",
    "            # print(f'acc : {acc}')\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch + 1,\n",
    "            #     'state_dict_backbone': models['backbone'].state_dict(),\n",
    "            #     'state_dict_module': models['module'].state_dict()\n",
    "            # },\n",
    "            # f'{checkpoint_dir}/crnn_lloss_{int(time.time())}.pth')\n",
    "    print('>> Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task():   \n",
    "    for trial in range(TRIALS):\n",
    "        # Initialize a labeled dataset by randomly sampling K=ADDENDUM=1,000 data points from the entire dataset.\n",
    "        indices = list(range(NUM_TRAIN))\n",
    "        random.shuffle(indices)\n",
    "        labeled_set = indices[:ADDENDUM]\n",
    "        unlabeled_set = indices[ADDENDUM:]\n",
    "        \n",
    "        train_loader = DataLoader(trainset, batch_size=BATCH, \n",
    "                                    sampler=SubsetRandomSampler(labeled_set), \n",
    "                                    pin_memory=True)\n",
    "        test_loader  = DataLoader(testset, batch_size=BATCH, shuffle=True)\n",
    "        dataloaders  = {'train': train_loader, 'test': test_loader}\n",
    "        \n",
    "        # Model\n",
    "        crnn_model    = crnn.CRNN(in_channels=1, output=num_class).cuda()\n",
    "        loss_module = lossnet.LossNet().cuda()\n",
    "        models      = {'backbone': crnn_model, 'module': loss_module}\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Active learning cycles\n",
    "        for cycle in range(CYCLES):\n",
    "            # Initialize Model weights Not Loss Prediction Module weights\n",
    "            models['backbone'].reset_parameters()\n",
    "            # models['module'].reset_parameters()\n",
    "\n",
    "            # Loss, criterion and scheduler (re)initialization\n",
    "            criterion      = nn.CTCLoss(reduction='none') # nn.CrossEntropyLoss(reduction='none')\n",
    "            optim_backbone = optim.Adam(models['backbone'].parameters(), lr=LR,\n",
    "                                    weight_decay=WDECAY)\n",
    "            optim_module   = optim.SGD(models['module'].parameters(), lr=LR, \n",
    "                                    momentum=MOMENTUM, weight_decay=WDECAY)\n",
    "\n",
    "            optimizers = {'backbone': optim_backbone, 'module': optim_module}\n",
    "\n",
    "            # Training and test\n",
    "            train(models, criterion, optimizers, dataloaders, EPOCH, EPOCHL)\n",
    "            acc = test(models, criterion, dataloaders, mode='test')\n",
    "            print('Trial {}/{} || Cycle {}/{} || Label set size {}: Test acc {}'.format(trial+1, TRIALS, cycle+1, CYCLES, len(labeled_set), acc))\n",
    "\n",
    "\n",
    "            # Update the labeled dataset via loss prediction-based uncertainty measurement\n",
    "\n",
    "            # Randomly sample 10000 unlabeled data points\n",
    "            random.shuffle(unlabeled_set)\n",
    "            subset = unlabeled_set[:SUBSET]\n",
    "\n",
    "            # Create unlabeled dataloader for the unlabeled subset\n",
    "            unlabeled_loader = DataLoader(unlabeledset, batch_size=BATCH, \n",
    "                                            sampler=SubsetSequentialSampler(subset), # more convenient if we maintain the order of subset\n",
    "                                            pin_memory=True)\n",
    "\n",
    "            # Measure uncertainty of each data points in the subset\n",
    "            uncertainty = get_uncertainty(models, criterion, unlabeled_loader)\n",
    "\n",
    "            # Index in ascending order\n",
    "            arg = np.argsort(uncertainty)\n",
    "            \n",
    "            # Update the labeled dataset and the unlabeled dataset, respectively\n",
    "            labeled_set += list(torch.tensor(subset)[arg][-ADDENDUM:].numpy())\n",
    "            unlabeled_set = list(torch.tensor(subset)[arg][:-ADDENDUM].numpy()) + unlabeled_set[SUBSET:]\n",
    "\n",
    "            # Create a new dataloader for the updated labeled dataset\n",
    "            dataloaders['train'] = DataLoader(trainset, batch_size=BATCH, \n",
    "                                                sampler=SubsetRandomSampler(labeled_set), \n",
    "                                                pin_memory=True)\n",
    "        \n",
    "        checkpoint_dir = os.path.join('./checkpoints', 'trial', 'weights')\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        # Save a checkpoint\n",
    "        torch.save({\n",
    "                    'trial': trial + 1,\n",
    "                    'state_dict_backbone': models['backbone'].state_dict(),\n",
    "                    'state_dict_module': models['module'].state_dict()\n",
    "                },\n",
    "                f'{checkpoint_dir}/crnn_lloss_{int(time.time())}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.07211538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000029vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000029vscode-remote?line=1'>2</a>\u001b[0m     main_task()\n",
      "\u001b[1;32m/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb Cell 13'\u001b[0m in \u001b[0;36mmain_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000013vscode-remote?line=33'>34</a>\u001b[0m optimizers \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbackbone\u001b[39m\u001b[39m'\u001b[39m: optim_backbone, \u001b[39m'\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m'\u001b[39m: optim_module}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000013vscode-remote?line=35'>36</a>\u001b[0m \u001b[39m# Training and test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000013vscode-remote?line=36'>37</a>\u001b[0m train(models, criterion, optimizers, dataloaders, EPOCH, EPOCHL)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000013vscode-remote?line=37'>38</a>\u001b[0m acc \u001b[39m=\u001b[39m test(models, criterion, dataloaders, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000013vscode-remote?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrial \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m || Cycle \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m || Label set size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: Test acc \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(trial\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, TRIALS, cycle\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, CYCLES, \u001b[39mlen\u001b[39m(labeled_set), acc))\n",
      "\u001b[1;32m/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb Cell 12'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, criterion, optimizers, dataloaders, num_epochs, epoch_loss)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000012vscode-remote?line=4'>5</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(checkpoint_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000012vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000012vscode-remote?line=7'>8</a>\u001b[0m     train_epoch(models, criterion, optimizers, dataloaders, epoch, epoch_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000012vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39m# Save a checkpoint\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000012vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb Cell 10'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(models, criterion, optimizers, dataloaders, epoch, epoch_loss)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mglobal\u001b[39;00m iters\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# loss_cum_1, loss_cum_2 = 0, 0\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000010vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(dataloaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000010vscode-remote?line=12'>13</a>\u001b[0m     inputs \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000010vscode-remote?line=13'>14</a>\u001b[0m     labels \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb Cell 5'\u001b[0m in \u001b[0;36mCaptchaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39miloc[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000005vscode-remote?line=10'>11</a>\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, data[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m]))\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mL\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m     label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Borange/home/jyji/devleop/TEMP/2022_bigdata/learning_loss/CRNN_with_LLOSS.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py:889\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=846'>847</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=847'>848</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=848'>849</a>\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=849'>850</a>\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=885'>886</a>\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=886'>887</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=888'>889</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=890'>891</a>\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=891'>892</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/Image.py?line=892'>893</a>\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=246'>247</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=247'>248</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=248'>249</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=249'>250</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=251'>252</a>\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=252'>253</a>\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=253'>254</a>\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/jyji/miniconda3/envs/mytorch/lib/python3.8/site-packages/PIL/ImageFile.py?line=254'>255</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main_task()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4a27c98caeaa5630be10b8d406a4608184d11e4add7ee29d27ce8c7f4d0bc9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
